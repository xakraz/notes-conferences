# 20170329_kubeCon_1.2.6

<!-- MarkdownTOC -->

- [2 - Presentations](#2---presentations)
  - [2.6 - OnPremise k8s](#26---onpremise-k8s)
    - [Intro](#intro)
    - [Accessing Pods](#accessing-pods)
    - [Architectures](#architectures)
    - [Notes](#notes)

<!-- /MarkdownTOC -->




## 2 - Presentations

### 2.6 - OnPremise k8s

#### Intro

Business: Technology is the problem
Tech: Monolith is the problem
-> Micro services

Results:
* 1 Problem
* 1000 Problems

Real life:
* Provisioning is too long
* 1000 VMs take time to administrate
* ...

New stack
* CoreOS
* k8s

#### Accessing Pods

NetworkPorts / Ingress

NP:
* Dynamicly allocated by k8s
* With 1 LB in front (F5), too dynamic

Ingress:
* Dedicated LB watching k8s API

##### WARNING Notes: Ingress and reloads

1. Nginx ingress (default with k8s)
2. Do upstream node lexical ordering based on IPs
3. When each Ingress is reloaded on evey k8s nodes, the 1st pod get all the traffic
-> FAILS
-> Triggers and other reload and remove the failed pod from the upstream node list
-> The new 1st pod fails ...


#### Architectures

1 Pod =
* App
* FluentD
* CollectD + Carbon

2 k8s clusters:
* Dev / QA
* Preprod / Prod

Each App have 1 dedicated namespace / environment
* app1-dev
* app1-qa
* app1-preprod
* qpp1-prod


#### Notes

Zero Downtime deployment:
* Leverage the `lifecycle:preStop` statement of a deployment object

CI/CD
* CI is fully automated
* CD has "gates" (Manual validation)
* Every stages have canaries pods


